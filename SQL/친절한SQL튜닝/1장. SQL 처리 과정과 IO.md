# 1장. SQL 처리 과정과 I/O

#### 목차
1. SQL 파싱과 최적화
2. SQL 공유 및 재사용
3. 데이터 저장 구조 및 I/O 메커니즘

<br>

---

<br>

## 1. SQL 파싱과 최적화
### [ SQL / 옵티마이저 / SQL 최적화 ]
#### SQL
* Sturectured Query Language
* 구조적, 집합적, 선언적 질의 언어

#### 옵티마이저
* DBMS 내부 엔진
* 사용자가 원하는 작업을 가장 효율적으로 수행할 수 있는 최적의 데이터 엑세스 경로를 선택해주는 핵심 엔진
* 결과 집합은 구조적, 집합적으로 선언하지만 그 결과 집합을 만드내는 프로시저가 필요한데, 그런 프로시저를 만들어 내는 것이 SQL 옵티마이저
* 옵티마이저가 프로그래밍을 대신해주는 셈

#### SQL 최적화
* DBMS 내부에서 프로시저를 작성하고 컴파일해서 실행 가능한 상태로 만드는 전 과정

<br>

### [ SQL 최적화 ]
#### 최적화 과정
1. SQL 파싱
   * 사용자로부터 SQL을 전달 받으면, SQL 파서가 파싱 진행
   * 파싱 트리 생성 → Syntax 체크 (문법적 오류) → Semantic 체크 (의미상 오류)
2. SQL 최적화
   * 옵티마이저가 수집한 통계정보를 바탕으로 다양한 실행경로 생성/비교 후 선택
3. 로우 소스 생성
   * 옵티마이저가 선택한 실행경로를 실제 실행 가능한 코드 또는 프로시저 형태로 포멧팅하는 단계
  
<br>

### [ SQL 옵티마이저 ]
#### 옵티마이저의 최적화 단계
1. 사용자로부터 전달받은 쿼리를 수행하는 데 후보 실행계획들을 찾아냄
2. 데이터 딕셔너리에 미리 수집해둔 오브젝트/시스템 통계정보를 이용해 각 실행계획의 예상비용 산정
3. 최저 비용 실행계획 선택

<br>

### [ 실행계획과 비용 ]
#### 실행계획
* 옵티마이저가 생성한 처리 절차를 사용자가 확인할 수 있게 트리 구조로 표현한 것
<img width="549" height="174" alt="image" src="https://github.com/user-attachments/assets/26d6e05f-8339-4e9a-85f9-eed6e14affef" />

#### 비용(Cost)
* 옵티마이저가 실행경로를 선택하는 근거
* 쿼리를 수행하는 동안 발생할 것으로 예상하는 I/O 횟수 또는 예상 소요시간을 표현한 값

<br>

### [ 옵티마이저 힌트 ]
* 옵티마이저도 가끔 한계가 있기 때문에 힌트를 이용해 데이터 엑세스 경로를 바꿀 수 있음
* 업무 내용은 옵티마이저는 모르고 개발자만 알고 있기 때문
#### 힌트 사용법
* 주석 기호에 '+' 붙이기
* 예시 : /*+ INDEX(컬럼) */
#### 힌트 사용 시 주의사항
* 힌트 안에 인자는 ','(콤마)를 사용할 수 있으나, 힌트와 힌트 사이에는 사용할 수 없음
* 인자의 테이블 지정 시, 스키마명은 명시할 수 없음
* FROM 절 테이블명 앞에 ALIAS를 지정했다면, 힌트의 인자에도 ALIAS를 사용해야 함

<br>

---

<br>

## 2. SQL 공유 및 재사용
### [ 소프트파싱 vs 하드파싱 ]

사용자가 SQL문을 전달하면 DBMS는 SQL을 파싱한 후 해당 SQL이 라이브러리 캐시에 존재하는지부터 확인하는데..

#### 소프트파싱
* 해당 SQL을 라이브러리 캐시에서 찾으면 곧바로 실행단계로 넘어가는 데, 이를 소프트 파싱이라고 함

#### 하드 파싱
* 해당 SQL을 라이브러리 캐시에서 찾지 못하면 최적화 및 로우 소스 생성 단계까지 모두 거쳐야 하는데, 이를 하드 파싱이라고 함

<img width="548" height="215" alt="image" src="https://github.com/user-attachments/assets/a66e6bb2-8268-4562-9dbf-af5e11253ad6" />

<br>

라이브러리 캐시?
* SQL 파싱, 최적화, 로우 소스 생성 과정을 거쳐 생성한 내부 프로시저를 반복 재사용할 수 있도록 캐싱해 두는 메모리 공간
* 라이브러리 캐시는 SGA 구성요소
  * SGA : System Global Area, 서버 프로세스와 백그라운드 프로세스가 공통으로 액세스하는 데이터와 제어 구조를 캐싱하는 메모리 공간
  * <img width="460" height="243" alt="image" src="https://github.com/user-attachments/assets/fc10e3e5-5d56-46e6-a70c-428999f086f6" />
* 라이브러리 캐시가 필요한 이유 : 하드 파싱으로 생성한 프로시저(최적화라는 어려운, 하드한 작업을 거쳐 생성한 내부 프로시저)를 한 번만 사용하고 버린다면 이렇게 비효율 적일 수가 없지..
* 라이브러리 캐시 조회 테이블 : `V$SQL`

<br>

SQL 최적화 시, 옵티마이저가 사용하는 정보
* 테이블, 컬럼, 인덱스 구조에 관한 기본 정보
* 오브젝트 통계 : 테이블, 인덱스, 컬럼 통계
* 시스템 통계 : CPU 속도, Single Block I/O 속도, Multiblock I/O 속도 등
* 옵티마이저 관련 파라미터

<br>

### [ 바인드 변수의 중요성 ]

보통 오브젝트는 컴파일 한 상태로 딕셔너리에 저장되고, 실행할 때 라이브러리 캐시에 적재되며 여러 사용자가 공유하면서 재사용을 함.

SQL 또한 처음으로 실행할 때 라이브러리 캐시에 적재됨 (SQL 전체 텍스트가 적재됨)

그러나.. 오브젝트처럼 SQL을 영구 저장해서 사용할 수 없음 (변수가 계속 달라지면 텍스트가 달라지기 때문)

#### 바인드 변수
파라미터 Driven 방식으로 SQL을 작성하는 방법
예시 : `SELECT * FROM CUSTOMER WHERE LOGIN_ID = :1`

<br>

---

<br>

## 3. 데이터 저장 구조 및 I/O 메커니즘
I/O 튜닝은 곧.. SQL 튜닝
디스크 I/O가 SQL 성능을 좌우한다!

### [SQL이 느린 이유]
I/O(구체적으로 디스크 I/O) 때문.

프로세스는 정해진 OS 함수를 호출하고 (I/O Call) CPU를 반환한 채 알람을 설정하고 대기 큐에서 잠을 자는데, 열심히 일해야 할 프로세스가 한가하게 잠을 자고 있으니 I/O가 많으면 성능이 느릴 수 밖에..

#### I/O는 잠(Sleep)이다.
OS 또는 I/O 서브시스템이 I/O를 처리하는 동안 프로세스는 잠을 자기 때문에
* 프로세스는 정해진 OS 함수를 호출하고 (I/O Call) CPU를 반환한 채 알람을 설정하고, 대기 큐에서 잠을 잔다.
 
#### 프로세스
* 실행 중인 프로그램
* 생명주기를 가짐
  * 여러 프로세스가 하나의 CPU를 공유할 수 있지만, 특정 순간에는 하나의 프로세스만 CPU를 사용할 수 있기 때문에 이런 메커니즘이 필요함. 
    * <img width="576" height="287" alt="image" src="https://github.com/user-attachments/assets/974f8c77-b239-4da1-a6e6-9f0a13d03b32" />

<br>

### [데이터베이스 저장 구조]
데이터를 저장하려면 먼저 테이블스페이스 생성해야 함.
#### 테이블스페이스
세그먼트를 담는 콘테이너로서, 여러 개의 데이터파일로 구성

<img width="734" height="521" alt="image" src="https://github.com/user-attachments/assets/ba32cf10-288d-4632-843a-7412f22e7f47" />

<img width="717" height="380" alt="image" src="https://github.com/user-attachments/assets/8345895a-e71d-4dde-b036-b46222039bfa" />


* 블록 : 데이터를 읽고 쓰는 단위
  * 실제로 레코드를 저장하는 공간
  * 한 블록에 저장된 레코드는 모두 같은 테이블의 레코드. 
* 익스텐트 : 공간을 확장하는 단위. 연속된 블록 집합
  * 공간이 부족해지면 해당 오브젝트가 속한 테이블스페이스로부터 익스텐트를 추가로 할당 받음
  * 세그먼트에 할당된 모든 익스텐트가 같은 파일데이터에 위치하지 않을 수 있음.
  * 파일 경합을 줄이기 위해 DBMS가 데이터를 여러 데이터파일로 분산해서 저장하기 때문
* 세그먼트 : 데이터 저장공간이 필요한 오브젝트 (테이블, 인덱스, 파티션, LOB 등)
* 테이블스페이스 : 세그먼트를 담는 콘테이너
* 데이터파일 : 디스크 상의 물리적인 OS 파일

<br>

### [블록 단위 I/O]
#### 블록
DBMS가 데이터를 읽고 쓰는 단위
* 데이터 I/O 단위가 블록이므로 특정 레코드 하나를 읽고 싶어도 해당 블록을 통째로 읽음
* 오라클은 기본적으로 8KB 크기의 블록을 사용하므로, 1Byte를 읽기 위해 8KB를 읽는 셈
* 테이블뿐만 아니라 인덱스도 블록 단위로 데이터를 읽고 씀

<img width="734" height="530" alt="image" src="https://github.com/user-attachments/assets/b2a2427a-f6d3-4ee1-bc97-132a04de19aa" />

<br>

### [시퀀셜 엑세스 vs 랜덤 엑세스]
테이블/인덱스 블록을 엑세스 하는 방식으로 두가지가 있음
<img width="731" height="534" alt="image" src="https://github.com/user-attachments/assets/0bd5a81d-9ded-4657-ac1c-5d2adf17c59b" />

* 실선 : 시퀀셜 엑세스
* 점선 : 랜덤 엑세스 

#### 시퀀셜 엑세스
* 논리적 또는 물리적으로 연결된 순서에 따라 차례대로 블록을 읽는 방법
* 인덱스
  * 인덱스 리프 블록은 앞뒤를 가리키는 주소값을 통해 논리적으로 서로 연결되어 있음
  * 이 주소 값에 따라 앞 또는 뒤로 순차적으로 스캔하는 방식이 시퀀셜 엑세스
* 테이블
  * 블록 간에는 서로 논리적인 연결고리는 없음
  * 오라클은 세그먼트에 할당된 익스텐트 목록을 세그먼트 헤더에 맵으로 관리하는데, 익스텐트 맵은 각 익스텐트의 첫 번째 블록 주소 값을 가짐.
  * 읽어야 할 익스텐트 목록을 익스텐트 맵에서 얻고, 각 익스텐트의 첫 번째 블록 뒤에 연속해서 저장된 블록 순서대로 읽음 (Full Table Scan)

#### 랜덤 엑세스
* 논리적, 물리적인 순서를 따르지 않고, 레코드 하나를 읽기 위해 한 블록씩 접근하는 방식

<br>

### [논리적 I/O vs 물리적 I/O]
#### DB 버퍼캐시
DB 버퍼 캐시 = 데이터 캐시
<img width="547" height="267" alt="image" src="https://github.com/user-attachments/assets/6095502f-0aca-4fc4-9a8f-f42a7a24c078" />

디스크에서 어렵게 읽은 데이터 블록을 캐싱 함으로써 같은 블록에 대한 반복적인 I/O Call을 줄이려는 목적
<img width="657" height="293" alt="image" src="https://github.com/user-attachments/assets/d3a9f021-dce4-4f76-a9ec-68108ff4744c" />

※ 버퍼 캐시 사이즈 확인 방법 : `V$SGA`

#### 데이터 탐색
* 서버 프로세스와 데이터파일 사이에 버퍼캐시가 있으므로, 데이터 블록을 읽을 땐 항상 버퍼캐시부터 탐색
* 버퍼 캐시는 공유메모리 영역이므로 같은 블록을 읽는 다른 프로세스도 득을 봄

#### [논리적 블록 I/O vs 물리적 블록 I/O]
<img width="680" height="325" alt="image" src="https://github.com/user-attachments/assets/83e655e6-ef8d-429e-99e6-3f306f603794" />

**논리적 블록**
* SQL을 처리하는 과정에서 발생한 총 블록 I/O
* 메모리상의 버퍼 캐시를 경유하므로 메모리 I/O가 곧 논리적 I/O

**물리적 블록 I/O**
* 디스크에서 발생한 총 블록 I/O
* SQL 처리 도중 읽어야 할 블록을 버퍼 캐시에서 찾지 못할 때만 디스크에서 액세스

메모리 I/O는 전기적 신호이고, 디스크 I/O는 액세스 암을 통해 물리적 작용이 일어나므로 메모리 I/O에 비해 상당히 느림. (10000배쯤..)


#### 버퍼캐시 히트율
* 버퍼캐시 효율을 측정하는 데 전통적으로 가장 많이 사용해 온 지표.
* 읽은 전체 블록 중에서 물리적인 디스크 I/O를 수반하지 않고 곧바로 메모리에서 찾은 비율
* BCHR : Buffer Cache Hit Ratio
<img width="588" height="87" alt="image" src="https://github.com/user-attachments/assets/c9eec92a-06d5-4516-9004-908e0f190991" />

#### 중요한 성능 원리
* 물리적 I/O가 성능을 결정하지만, 실제 SQL 성능을 향상하려면 논리적 I/O를 줄여야 한다. ★★★
  * 물리적 I/O는 시스템 상황에 의해 결정되는 통제 불가능한 외생변수이므로.
* 논리적 I/O는 어떻게 줄일까? SQL 튜닝으로.

#### BCHR 실제로 계산해보기
<img width="675" height="190" alt="image" src="https://github.com/user-attachments/assets/d87382b9-886c-454d-9a63-493cbe3ae3b9" />
※ SQL 트레이스를 통해 수집한 Call 통계 정보
* 논리적 I/O : Query와 Current 항목 더한 값
  * 즉, SQL 수행 과정에 읽은 총 블록 개수
* 물리적 I/O : DISK 항목
  * 디스크에서 물리적으로 읽은 블록 개수 

**BCHR 계산**
블록을 읽을 때는 해당 블록을 먼저 버퍼캐시에서 찾아보고 없을 때만 디스크에서 읽는데, 디스크에서 곧바로 읽는 것이 아니라 먼저 버퍼캐시에 적재하고서 읽음.
따라서 DB 버퍼캐시에서 읽은 1,364,044개 블록에는 디스크에서 읽은 601,458개 블록이 이미 포함되어 있음
`BCHR = (1 - (Disk / (Query + Current))) X 100

#### BCHR 주의 사항
* BCHR이 SQL 성능을 좌우하지만, 높다고 해서 효율적인 SQL을 의미하지는 않음.
* 같은 블록을 비효율적으로 반복해서 읽어도 BCHR이 높아짐.

<br>

### [Single Block I/O vs Multiblock I/O]
캐시에서 찾지 못한 데이터 블록은 I/O Call을 통해 디스크에서 DB 버퍼캐시로 적재하고서 읽음.

#### Single Block I/O
I/O Call 할 때, 한 번에 한 블록씩 요청해서 적재하는 방식
* Single Block I/O 방식을 사용하는 경우
  * 인덱스를 이용할 때는 기본적으로 인덱스와 테이블 블록 모두 해당 방식 사용 

#### Multi Block I/O
I/O Call 할 때, 한 번에 여러 블록씩 요청해서 적재하는 방식
* 많은 데이터 블록을 읽을 때 효율적
  * 테이블이 클수록 Multiblock I/O 단위도 크면 좋음
  * 프로세스가 대기 상태가 되는 횟수를 줄이기 때문
* Multiblock I/O 단위 정하는 방법 : db_file_multiblock_read_count 파라미터로 정함
* Multi Block I/O 방식을 사용하는 경우
  * 인덱스를 이용하지 않고, 테이블 전체를 스캔할 때 해당 방식 사용
 
**Multi Block I/O 추가설명**
캐시에서 찾지 못한 특정 블록을 읽기 위해 I/O Call 할 때 디스크 상에 그 블록과 인접한 블록들을 한꺼번에 읽어 캐시에 미리 적재하는 기능
* 인접한 블록이란 익스텐트에 속한 블록을 의미하므로..
* Multiblock I/O 방식으로 읽더라도 익스텐트 경계를 넘지 못함.

<br>

### [Table Full Scan vs Index Range Scan]
테이블에 저장된 데이터를 읽는 방식 2가지
#### Table Full Scan
* 테이블 전체를 스캔해서 읽는 방식
* 테이블에 속한 블록 전체를 읽어서 원하는 데이터 찾는 방식
* 시퀀셜 엑세스와 Multiblock I/O 방식으로 디스크 블록을 읽음

#### Index Range Scan
* 인덱스를 이용한 테이블 읽는 방식
* 인덱스에서 일정량 스캔하면서 얻은 ROWID로 테이블 레코드를 찾아가는 방식
  * ROWID : 테이블 레코드가 디스크 상에 어디 저장됐는지를 가리키느 위치 정보
* 랜덤 엑세스와 Single Block I/O 방식으로 디스크 블록을 읽음

#### Table Full Scan 고정관념
* Table Full Scan 찾아내기식 실행계획 분석은 실제로 SQL 성능을 향상하는 데 큰 도움이 되지 않음 (인덱스 사용해야 하는 상황에서는 의미 있음)
* 인덱스도 SQL 성능을 떨어뜨리는 경우도 상당히 많음
* 한 번에 많은 데이터를 처리하는 집계용 SQL과 배치 프로그램이 특히 그럼. 이때 상당수는 Table Full Scan으로 유도하면 성능이 빨라짐
* 조인을 포함한 SQL이면, 조인 메소드로 해서 조인을 선택해주면 됨.
* **읽을 데이터가 일정량 넘으면 인덱스보다 Table Full Scan이 유리함**

#### 인덱스를 사용하는데 성능이 더 느린 이유
* 큰 테이블에서 소량 데이터를 검색할 때는 반드시 인덱스 이용
* 많은 데이터를 읽을 때는 성능이 느림
* 읽었던 블록을 반복해서 읽는 비효율이 있기 때문에 많은 데이터를 읽을 때 논리적인 블록 I/O 측면에서도 불리함.

<br>

### [캐시 탐색 메커니즘]
버퍼캐시 탐색 과정을 거치는 경우
* 인덱스 루트 블록을 읽을 때
* 인덱스 루트 블록에서 얻은 주소 정보로 브랜치 블록을 읽을 때
* 인덱스 브랜치 블록에서 얻은 주소 정보로 리프 블록을 읽을 때
* 인덱스 리프 블록에서 얻은 주소 정보로 테이블 블록을 읽을 떄
* 테이블 블록을 Full Scan 할 때

<br>

DBMS는 버퍼 캐시를 해시 구조로 관리함 (아래 참고)
<img width="653" height="478" alt="image" src="https://github.com/user-attachments/assets/1060e5c2-7110-4b0d-844e-a114ead1ece4" />

#### 버퍼 캐시 탐색 메커니즘
버퍼 캐시에서 블록을 찾을 때 해시 알고리즘으로 버퍼 헤더를 찾고, 거기서 얻은 포인터로 블록을 액세스 하는 방식 사용

#### 메모리 공유자원에 대한 엑세스 직렬화
* 버퍼캐시는 SGA 구성요소이므로 버퍼캐시에 캐싱된 버퍼블록은 모두 공유자원
* 두 개 이상 프로세스가 동시에 접근하려고 할 때 문제 발생할 수 있음
* 따라서 자원을 공유하는 것처럼 보여도 내부에서는 한 프로세스씩 순차적으로 접근하도록 구현해야 함.
* 이를 위해 **직렬화 메커니즘이 필요** (쉽게 말해, 줄 세우기)
* 이런 줄서기가 가능하도록 지원하는 메커니즘이 **래치**

#### 캐시버퍼 체인 래치
* 대량의 데이터를 읽을 때 모든 블록에 대해 해시 체인을 탐색함
* DBA(Data Block Address)를 해시 함수에 입력하고, 거기서 반환된 값으로 스캔해야 할 해시 체인을 찾음
* 해시 체인을 스캔하는 동안 다른 프로세스가 체인 구조를 변경하는 일이 생기면 곤란하므로, 이를 막기 위해 해시 체인 래치가 존재함
* 키를 획득한 프로세스만이 체인으로 진입 가능

#### 래치
* SGA를 구성하는 서브 캐시마다 별도의 래치가 존재
* 버퍼캐시에는 캐시버퍼 체인 래치, 캐시버퍼 LRU 체인 래치 등이 작동함.
* 빠른 데이터베이스를 구현하려면 버퍼캐시 히트율을 높여야하지만 캐시 I/O도 생각만큼 빠르지 않을 수 있음 (래치에 의한 경합이 생길 수 있기 때문)
* 캐시버퍼 체인뿐만 아니라 버퍼블록 자체에도 직렬화 메커니즘 존재하는데, * 이를 **버퍼 Lock**이라 함
* 직렬화 메커니즘에 의한 캐시 경합을 줄이려면, SQL 튜닝을 통해 쿼리 일량(논리적I/O) 자체를 줄여야 함
  
#### 버퍼 Lock
* 읽고자 하는 블록을 찾았으면 캐시버퍼 체인 래치를 곧바로 해제해야 함
  * 그래야 다른 프로세스들이 작업 재게 가능
* 그런데 래치를 해제한 상태로 버퍼블록 데이터를 읽고 쓰는 도중 후행 프로세스가 하필 같은 블록에 접근해서 데이터를 읽고 쓴다면 데이터 정합성에 문제가 생길 수 있음. 이를 방지하기 위해 버퍼 Lock을 사용.
* 캐시버퍼 체인 래치를 해제하기 전에 버퍼 헤더에 Lock을 설정함으로써 버퍼블록 자체에 대한 직렬화 문제를 해결하는 것. 
